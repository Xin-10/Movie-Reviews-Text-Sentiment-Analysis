{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cczu26HPzn_T"
   },
   "source": [
    "# Text classification with linear models (binary classification)\n",
    "\n",
    "# Introduction\n",
    "\n",
    "**Text classification**, broadly, is the process of categorizing text into pre-defined groups/classes. In practice, text classification looks like a laundry list of common applied tasks:\n",
    "- Sentiment Analysis, or understanding the view / attitude / feeling / emotion towards a situation or event expressed in a text;\n",
    "- Topic Labeling, or identifying the theme or topic present in the text (e.g. analyzing the topics of news articles)\n",
    "- Spam detection, or determining whether a message (often email) is spam or not.\n",
    "- User attribute inference, or guessing the gender, age, occupation, author, or other factors based on their posts on social media platforms.\n",
    "\n",
    "Text classification methods let us **organize unstructured text** to extract value from or gain insights into it. They're commonly deployed on a wide variety of corpuses:\n",
    "- social media messages\n",
    "- emails\n",
    "- online conversations (chat-bots)\n",
    "- websites\n",
    "- any other text data that could reasonably have categories!\n",
    "\n",
    "Modern text classification methods use a machine learning approach in which we\n",
    "1. train a classifier using pre-labeled data\n",
    "2. test the classifier on held out data, and then\n",
    "3. apply the classifier to make predictions on un-labeled data.\n",
    "\n",
    "This approach is nice in that it is fast, effective, and accurate, but it does require a significant amount of pre-labeled training data.\n",
    "\n",
    "    \n",
    "![classification.png](data:image/png;base64,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)\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tO-PZgh_zn_Y"
   },
   "source": [
    "# Overview\n",
    "In this assignment, we will practice building a machine learning system for binary sentiment classification of [IMDb](https://www.imdb.com/) movie reviews with the following guided tasks:\n",
    "\n",
    "In tasks Tasks 1 and 2, we will explore different text representation techniques: <br>\n",
    "- **Task-1**: exploring text representation with `TfidfVectorizer` <br>\n",
    "- **Task-2**: exploring text representation with embedding techniques (choose from [word2vec](https://www.cell.com/heliyon/fulltext/S2405-8440(18)35340-4) and OpenAI) <br>\n",
    "\n",
    "In Tasks 3 and 4, we will explore different parameter settings for our linear models: <br>\n",
    "- **Task-3**: comparing model performance with `penalty='l1'` VS `penalty='l2'` <br>\n",
    "- **Task-4**: exploring model performance with `C=0.1` VS `C=1` VS `C=10` <br>\n",
    "\n",
    "Lastly, in **Task 5** you will choose the best model from your exploration and conduct **error analysis** to understand and explain where the model fails <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjilLNfcphdp"
   },
   "source": [
    "# Data\n",
    "The dataset contains 50,000 IMDB movie reviews with an indicator for the sentiment (\"positive\" or \"negative\") of the review. More details can be found from the following resources:\n",
    "- [Data source](https://ai.stanford.edu/~amaas/data/sentiment/) <br>\n",
    "- [Paper: Learning Word Vectors for Sentiment Analysis](https://ai.stanford.edu/~ang/papers/acl11-WordVectorsSentimentAnalysis.pdf) <br>\n",
    "- Example review: https://www.imdb.com/title/tt0454921/reviews?ref_=tt_urv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Y2m-cEqzn_Y"
   },
   "outputs": [],
   "source": [
    "import time, os\n",
    "\n",
    "# scientific calculation packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# visualization packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# natural language processing packages\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# machine learning packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAxzfRZlzn_a"
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_e4GtLZ6zn_a"
   },
   "outputs": [],
   "source": [
    "# Read data from csv file to a pandas dataframe\n",
    "df_data = pd.read_csv('./IMDB Dataset.csv') # change to your path\n",
    "\n",
    "# check the data size and display the top-n data samples\n",
    "df_data.shape, display(df_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3I1Ae_inzn_c"
   },
   "source": [
    "**Note**: You can change parameter setting to view non-truncated dataframe with:\n",
    ">```Python\n",
    "pd.set_option('display.max_colwidth', None)\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahYhc3oyzn_c",
    "outputId": "58f7ef84-42e1-47b8-e2a9-5f849e7261ec"
   },
   "outputs": [],
   "source": [
    "# an example of a negative review\n",
    "df_data.iloc[10].sentiment, df_data.iloc[10].review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQCQ-ammzn_d"
   },
   "source": [
    "Check **missing** values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzvE0Q51zn_d",
    "outputId": "4536f9e1-90de-499d-d6a7-e732e8fc4e79"
   },
   "outputs": [],
   "source": [
    "df_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3mzhSvephdu"
   },
   "source": [
    "Remove **duplicate** samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyz_qbHhzn_d",
    "outputId": "00dd2530-6b5d-404a-a7a3-cfb42f02e271"
   },
   "outputs": [],
   "source": [
    "df_data = df_data.drop_duplicates(keep=\"first\")\n",
    "\n",
    "# check the number of training samples after remove duplication\n",
    "# reduce from 50,000 to 49582, we removed about 500 duplicate samples\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWJzKKTGphdu"
   },
   "source": [
    "## Explore the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M93Wk5E5phdu"
   },
   "source": [
    "Target variable: sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZ81jTNNphdu"
   },
   "source": [
    "Check the **distribution** of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_A86B_HEzn_e",
    "outputId": "15561ade-a1cb-43fc-8360-78b4de07daf6"
   },
   "outputs": [],
   "source": [
    "df_data.sentiment.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYILQ4aqzn_e"
   },
   "source": [
    "The dataset is **equally distributed (balanced)**, which is great for building a ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6TIM1Zmphdv"
   },
   "source": [
    "Next, we will convert the **sentiment labels to binary values** (e.g., 1 for postive and 0 for negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CklxDhXBphdv",
    "outputId": "d0b2a79f-86d3-4e19-8a16-a7355b3490f1"
   },
   "outputs": [],
   "source": [
    "df_data['label'] = df_data['sentiment'].map({'positive':1,'negative':0})\n",
    "df_data.head()[['review','sentiment','label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLoVJ3EWphdv"
   },
   "source": [
    "## Explore the feature variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-Pj3K7Mzn_e"
   },
   "source": [
    "Let's first check the **length** of the reviews (a common exploration for text data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ioXjkBXJzn_e",
    "outputId": "5276a008-8c1a-4b24-9be3-a4ab807ebd1c"
   },
   "outputs": [],
   "source": [
    "df_data['length'] = df_data['review'].apply(len) # number of characters\n",
    "df_data['length'].describe()\n",
    "# the describe function shows the mean, std, min, max of length of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVruSknQzn_f",
    "outputId": "6fb75ee5-c53b-41e6-b100-4bebf970a951"
   },
   "outputs": [],
   "source": [
    "# Add a new column 'length' to the dataframe\n",
    "df_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-QLolt0zn_f",
    "outputId": "99818767-df44-4909-9ce9-4bb30170193e"
   },
   "outputs": [],
   "source": [
    "# check the length distribution of positive and negative reviews\n",
    "# x: length of reviews; y: number of reviews fall into each interval\n",
    "df_data.hist(column='length', by='sentiment',bins=30, figsize=(12,4),\n",
    "             rwidth=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aGnvnrdzn_f"
   },
   "source": [
    "The distribution plot shows that there is no clear difference between postive and negative reviews in terms of length.\n",
    "\n",
    "We now have a basic understanding of the dataset after the initial exploration; let's go ahead and process the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4l-xeWEzn_g"
   },
   "source": [
    "### Text Data Preprocessing\n",
    "There are a large variety of potential text data preprocessing steps, including but not necessarily limited to:\n",
    "- text cleaning (e.g., removing special characters, emails, urls)\n",
    "- lowercasing (e.g., Happy New Year -> happy new year)\n",
    "- removing stopwords\n",
    "- stemming, or choping off the ends of words to transform words into their root forms (e.g., connected->connect)\n",
    "- lemmatization, or mapping a word to its root form (e.g., interesting -> interest)\n",
    "- normalization, or transforming a text into a standard form (abbreviations, misspellings, out-of-vocabulary words; e.g., gooood->good)\n",
    "- part-of-speech tagging (e.g., good -> ADJ)\n",
    "\n",
    "\n",
    "For our task of analyzing IMDb movie reviews data, we mainly focus on **text cleaning**, such as removing:\n",
    "\n",
    "> HTML tags <br>\n",
    "> special / non-alphabetic characters <br>\n",
    "> url <br>\n",
    "> emails <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lru9PcYRzn_g",
    "outputId": "b356d16d-c99e-478f-dc76-49ea1559b9e7"
   },
   "outputs": [],
   "source": [
    "# Here is an example of the review that need further cleaning.\n",
    "df_data.review[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C0YdG1zJzn_g"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import re, string\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaG1Wu_cphdx"
   },
   "source": [
    "We define two functions to **clean** the text data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebKPnqTOzn_g"
   },
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    \"\"\"\n",
    "    Expand contractions into normal words\n",
    "    \"\"\"\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase) # prime\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "\n",
    "    return phrase\n",
    "\n",
    "def clean_text(df):\n",
    "    \"\"\"\n",
    "    Clean the review texts\n",
    "    \"\"\"\n",
    "    cleaned_review = []\n",
    "\n",
    "    for review_text in tqdm(df['review']):\n",
    "\n",
    "        # expand contractions\n",
    "        review_text = decontracted(review_text)\n",
    "\n",
    "        # remove html tags\n",
    "        review_text = BeautifulSoup(review_text, 'lxml').get_text().strip() # re.sub(r'<.*?>', '', text)\n",
    "\n",
    "        # remove non-alphabetic characters\n",
    "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "\n",
    "        # remove url\n",
    "        review_text = re.sub(r'https?://\\S+|www\\.\\S+', '', review_text)\n",
    "\n",
    "        # Removing punctutation, string.punctuation in python consists of !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_{|}~`\n",
    "        review_text = review_text.translate(str.maketrans('', '', string.punctuation))\n",
    "        # ''.join([char for char in movie_text_data if char not in string.punctuation])\n",
    "\n",
    "        # remove emails\n",
    "        review_text = re.sub(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\", '', review_text)\n",
    "\n",
    "        cleaned_review.append(review_text)\n",
    "\n",
    "    return cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ut-4j0L_phdx",
    "outputId": "41f1b5d8-9076-4d4f-c033-be562189ae54"
   },
   "outputs": [],
   "source": [
    "df_data['cleaned_review'] = clean_text(df_data)\n",
    "\n",
    "df_data.head()[['review', 'cleaned_review', 'sentiment', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDgdfGwUzn_h",
    "outputId": "4915526e-bd04-46db-8845-e31bfad614b4"
   },
   "outputs": [],
   "source": [
    "# a review before and after cleaning, we can see that the punctuations and html tags are removed.\n",
    "\n",
    "print(df_data['review'][9],'\\n')\n",
    "\n",
    "print(df_data['cleaned_review'][9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lurOIz3zn_h"
   },
   "source": [
    "### Text Data Representation\n",
    "\n",
    "After cleaning the text data, we will transform it into numerical feature vectors that computers can understand (see the [sklearn documentation](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) for more). Recall from class that we have multiple possible **units of representation**, such as individual words, ngrams/phrases, or sentences. Additionally recall the three vectorization methods we discussed:\n",
    "\n",
    "- **`CountVectorizer`**: if we consider documents to be a bag of words with no order or context, we can just represent each document as a vector of word counts.\n",
    "- **`TfidfVectorizer`**: if we consider documents to be a bag of words with no order or context, then we may think that the words that appear often in a given document but which appear rarely across all documents are highly salient. `TfidfVectorizer`'s formalize this by dividing the term-frequency of a word in a given document by it's frequency across all documents.\n",
    "- **`Embeddings`**: Embeddings represent words as high-dimensional dense vectors which take into account the context and relative order of words. There are numerous ways to get embedding representations, such as word2vec, BERT, and GPT.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Arz20ZZrphdy"
   },
   "source": [
    "In the following section, we'll walk through transforming text with a **`CountVectorizer`** ([Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wDT1ULYphdy"
   },
   "outputs": [],
   "source": [
    "# we can check the pre-defined English stop words list\n",
    "# print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ML7B8BTzzn_h"
   },
   "outputs": [],
   "source": [
    "# we define your own stopwords list as the pre-defined one is not enough\n",
    "# Note that we exclude NO, NOR, NOT from the stop words as they play a key role\n",
    "stopwords= list(set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llaB4Cjtphdy",
    "outputId": "5bcba4a7-23a1-40a7-c04e-5d4ad3c05e1c"
   },
   "outputs": [],
   "source": [
    "# In the CountVectorizer, we ask it to lowercase the text and to use a self-defined stopwords list to remove stopwords\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words=stopwords, max_df=0.9, min_df=3, ngram_range=(1,1))\n",
    "\n",
    "# convert the cleaned reviews to vectors\n",
    "X = vectorizer.fit_transform(df_data.cleaned_review)\n",
    "# X is a 2-d matrix of vector representation of the cleaned reviews\n",
    "\n",
    "print(\"X.shape : \",X.shape)\n",
    "# X.shape: the number of samples, the number of features (size of vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k51_blZNphdy"
   },
   "source": [
    "Here is an example of the CountVectorizer representation for a movie review: it is represented as a vector of 47,352 elements, but only 136 of them are non-zero. That's incredibly **sparse**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpi6Wpndphdy",
    "outputId": "630b11cd-8b28-4a0f-863e-4969236d38ae"
   },
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2JeYiZGzn_i"
   },
   "source": [
    "## Finalize the feature matrix\n",
    "We prepare the feature matrix for model training by:\n",
    "1. Splitting the data into training and testing with 80:20 ratio (you can customize the ratio) and **shuffling** the data at the same time (random permutations of the collections)\n",
    "2. Assigning **a random state of 42 for reproducible output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBXJDDQcBtxL"
   },
   "outputs": [],
   "source": [
    "# Define the target variable: sentiment labels\n",
    "y = df_data.label.values\n",
    "\n",
    "print(\"y.shape : \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urK7_pmIzn_i",
    "outputId": "e4442237-7af8-44bd-df1b-d82795f333f1"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                 shuffle=True,\n",
    "                                                 random_state=42)\n",
    "# check data size after splitting\n",
    "print(\"Training data: X : {}, y : {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Testing data: X : {}, y : {}\".format(X_test.shape, y_test.shape))\n",
    "# After train test split, we get 39,665 samples in the training set and 9,917 samples in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k5epy9zZzn_i",
    "outputId": "41c88537-f956-4f21-b7a3-4f1aaa7222c3"
   },
   "outputs": [],
   "source": [
    "# check data distribution in train and test\n",
    "\n",
    "print(\"Training data distribution\", Counter(y_train))\n",
    "print(\"Testing data distribution\", Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ko1BSWMBzn_i"
   },
   "source": [
    "An **alternative choice** if you want to track the train and test index (we will need the index information for **error analysis**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWq20bzjzn_i",
    "outputId": "52632b73-3074-453c-d11f-a328ca7a4cab"
   },
   "outputs": [],
   "source": [
    "# Instead of splitting our data itself, split indices into either training rows\n",
    "# or testing rows.\n",
    "train_idx, test_idx = train_test_split(np.arange(df_data.shape[0]), test_size=0.2,\n",
    "                                       shuffle=True, random_state=42)\n",
    "\n",
    "len(train_idx), len(test_idx)\n",
    "print(\"Number of training examples:{}\".format(len(train_idx)))\n",
    "print(\"Number of testing examples:{}\".format(len(test_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dyZzV-5czn_j",
    "outputId": "34121c9d-7c48-41cd-f388-bb5e63e2c185"
   },
   "outputs": [],
   "source": [
    "# And then use these indices to split our data directly\n",
    "X_train = X[train_idx]\n",
    "y_train = y[train_idx]\n",
    "\n",
    "X_test = X[test_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "print(\"Training data: X_train : {}, y_train : {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Testing data: X_test : {}, y_test : {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_HIdiHuzn_j"
   },
   "source": [
    "# Model training and testing\n",
    "\n",
    "In this section, we will:\n",
    "- apply a Logistic Regression model to fit on the training data <br>\n",
    "- evaluate its performance on the testing data or cross-validate the model performance on the whole dataset <br>\n",
    "    - **quantitative** evaluation with precision, recall, f1, roc_auc <br>\n",
    "    - **qualitative** evaluation with important features <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PO-iyu7Ephd5"
   },
   "outputs": [],
   "source": [
    "# Create a LogisticRegression classifier\n",
    "lr_clf = LogisticRegression(penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZZy-2Udphd5",
    "outputId": "97d0b19b-2785-4845-ad31-4cafbc5f4efe"
   },
   "outputs": [],
   "source": [
    "# Fit the model on training data\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tl_1oqDyphd5"
   },
   "source": [
    "**Evaluate** the model performance on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kkFSPuWphd5",
    "outputId": "3a4bd251-e06b-409e-9955-7e05c4677874"
   },
   "outputs": [],
   "source": [
    "# with the \"score\" function (accuracy score)\n",
    "# Round it to the 3rd decimal (e.g., 0.800, 0.850, 0.862).\n",
    "float(\"{:.3f}\".format(lr_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsIn4PYkphd5"
   },
   "source": [
    "Alternatively, we can **cross-validate** model performance with the whole dataset. In brief, when cross-validating we:\n",
    "- split data into k folds <br>\n",
    "- train on k-1 folds, test on 1 fold, repeat k times (each sample appear once in the test set) <br>\n",
    "- report model performance for each fold <br>\n",
    "\n",
    "An example of this process is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ushtYpeiphd5",
    "outputId": "16475dfb-9d70-4537-eaf8-0b69ba05561b"
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(lr_clf, X, y, cv=5, scoring='precision')\n",
    "print(np.round(scores,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMwkku-9phd6"
   },
   "source": [
    "## Model evaluation\n",
    "We haven't fully covered the different [evaluation techniques](https://scikit-learn.org/stable/modules/model_evaluation.html) in the lecture yet, but here we provide a preview of the different methods you might consider for evaluating a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIomLvjJphd6"
   },
   "source": [
    "We use two common **quantitative evaluation** metrics:\n",
    "- Classification report, which shows us for precision, recall, and f1 <br>\n",
    "- `roc_auc`, which shows how well the model performs at different confidence thresholds <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6SVEC9_Uphd6",
    "outputId": "f377391f-de64-43b7-faed-f4976107bf35"
   },
   "outputs": [],
   "source": [
    "# apply the fitted model to prediction the label for the test data\n",
    "y_pred_test = lr_clf.predict(X_test)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GbiSWvWYphd6",
    "outputId": "7be20796-810f-4760-aec9-5b0e43389ba3"
   },
   "outputs": [],
   "source": [
    "# check the predicted probabilities of each test data\n",
    "y_predprob_test = lr_clf.predict_proba(X_test)\n",
    "np.round(y_predprob_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3i-huEUphd6",
    "outputId": "17045dd9-03e1-4188-9204-5e737f16d755"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "# micro average (averaging the total true positives, false negatives and false positives globally, true pos of one class / (all true pos + all false pos))\n",
    "# macro average (averaging the unweighted mean per label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQLkzWL8phd6"
   },
   "source": [
    "ROC curve ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feU_BWipphd7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_hi-M4Vqphd7"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true = y_test, y_score = y_predprob_test[:,1], pos_label=1)\n",
    "roc_auc = auc(fpr, tpr) # area under ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQqjoEIVphd7",
    "outputId": "9e292578-bb44-407b-ff4f-21aa309deb2d"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC (Receiver operating characteristic) curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eStZ6ds-phd7"
   },
   "source": [
    "According to the evaluation scores we can say that **the model is performing well**, and we will provide detailed explainations in the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qs2TJdYXphd7"
   },
   "source": [
    "**Qualitative evaluation**:\n",
    "\n",
    "We will identify the **important features** to validate model integrity in the context of sentiment classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXoOX6VBphd7"
   },
   "outputs": [],
   "source": [
    "feature_to_coef = {word: float(\"%.3f\" % coef) for word, coef in zip(vectorizer.get_feature_names_out(), lr_clf.coef_[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSB0rtt5phd7",
    "outputId": "3e05f31e-948e-4eeb-f2b4-a4e29903cb5c"
   },
   "outputs": [],
   "source": [
    "# Top features that are predictive of positive sentiment\n",
    "print(\"Top positive features:\")\n",
    "sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wWof_dY8phd7",
    "outputId": "22d3051a-0efe-4d2a-8bbe-420d64e374b2"
   },
   "outputs": [],
   "source": [
    "# Top features that are predictive of negative sentiment\n",
    "\n",
    "print(\"Top negative features:\")\n",
    "sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=False)[:10]\n",
    "# Most of top-10 negative words are reliable evidence of indicating negative sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCV1ffHjphd7"
   },
   "source": [
    "Most of the top predictive features make sense:\n",
    "- words like \"refreshing, hooked, superb\" are typically used to express positive sentiments; <br>\n",
    "- words like \"waste, worst\" are typically used to express negative sentiments; <br>\n",
    "\n",
    "**However**, some positive features like \"disappoint, underrated\" as well as negative features like \"generous\", are not clearly correlated with the sentiment. We will explore this further in the **error analysis** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4idiOBi3phd8"
   },
   "source": [
    "# Error analysis\n",
    "\n",
    "In this section, we will conduct error analysis to identify samples where the model fails to correctly predict the sentiment of a movie review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sH-xde0Kphd8",
    "outputId": "7f17922e-e0fd-4502-e872-cbfff576cb96"
   },
   "outputs": [],
   "source": [
    "df_test = df_data.iloc[test_idx]\n",
    "df_test['pred_label'] = y_pred_test\n",
    "df_test.head(3)[['review','label','pred_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UPmW3Ubphd8",
    "outputId": "13d6feaa-4663-4178-b9c7-c892185a3af1"
   },
   "outputs": [],
   "source": [
    "df_test[df_test['label'] != df_test['pred_label']].head()[['review','label','pred_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V0W-vp1Lphd8",
    "outputId": "15cf1468-dc9a-491b-a02c-68fd80fd42c5"
   },
   "outputs": [],
   "source": [
    "df_data.loc[47783]['cleaned_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGlRMiP_cjOZ"
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "# We'll use colors for convenience of viewing,\n",
    "# but your implementations do not need to do this.\n",
    "RED = '\\033[1;31;48m'\n",
    "BLUE = '\\033[1;34;48m'\n",
    "END = '\\033[1;37;0m'\n",
    "\n",
    "def interpretation(text, vectorizer, wrap_length=250, use_color=True):\n",
    "    \"\"\"\n",
    "    Annotate each word feature with the learned coefficient, and color based on\n",
    "    coefficient direction\n",
    "    \"\"\"\n",
    "    # Make the annotated string\n",
    "    analysis = []\n",
    "    for wd in text.split():\n",
    "        if wd in vectorizer.vocabulary_:\n",
    "            wd_id = vectorizer.vocabulary_[wd]\n",
    "            to_append = wd\n",
    "\n",
    "            # Red is more negative, blue is more positive\n",
    "            if use_color and lr_clf.coef_[0][wd_id] < 0:\n",
    "                to_append = RED + to_append + END\n",
    "            elif use_color and lr_clf.coef_[0][wd_id] > 0:\n",
    "                to_append = BLUE + to_append + END\n",
    "\n",
    "            to_append = to_append+'('+(\"%.3f\" % lr_clf.coef_[0][wd_id])+')'\n",
    "\n",
    "\n",
    "            analysis.append(to_append)\n",
    "        else:\n",
    "            analysis.append(wd)\n",
    "    result = ' '.join(analysis)\n",
    "\n",
    "    # Wrap the string for easier viewing\n",
    "    wrapper = textwrap.TextWrapper(width=wrap_length)\n",
    "    result = wrapper.fill(text=result)\n",
    "\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "beJ1lZFmgryE"
   },
   "outputs": [],
   "source": [
    "interpretation(df_data.loc[47783]['cleaned_review'],vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMZ41WOZphd8"
   },
   "source": [
    "# Tasks to complete\n",
    "\n",
    "In the previous section, we showed how to build a machine learning system for binary sentiment classification. Now it's your turn. In the following sections, you will build a similar model, exploring how different text representation techniques and model parameter settings affect model performance along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rgu90bkKphd9"
   },
   "source": [
    "#### **Task-1**: Text Representation with $TfidfVectorizer$\n",
    "\n",
    "In our example, we represented text with $CountVectorizer$. In this task, you will use a `TfidfVectorizer` to represent text as numeric data, before training a model and evaluating its performance. Specifically, you will:\n",
    "- Repeat our `CountVectorizer` feature creation process, but instead using a  `TfidfVectorizer` to create the feature matrix. Use the same parameter settings from our analysis.\n",
    "- **$fit$** a LogisticRegression classifier with the default parameter setting\n",
    "- Evaluate model performance based on the **$classification\\_report$**\n",
    "- Print the top-10 positive and negative features\n",
    "- Compare the model performance and top-n features with the previous results using `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5uBHJYQphd9"
   },
   "outputs": [],
   "source": [
    "# import TfidfVectorizer method\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase the text and to use the previous self-defined stopwords list to remove stopwords\n",
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words=stopwords, max_df=0.9, min_df=3, ngram_range=(1,1))\n",
    "\n",
    "#convert the cleaned reviews to vectors\n",
    "X = vectorizer.fit_transform(df_data.cleaned_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X.shape : \",X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target variable: sentiment labels\n",
    "y = df_data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y.shape : \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the train and test data numbers\n",
    "print(\"Training data: X : {}, y : {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Testing data: X : {}, y : {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data distribution\n",
    "print(\"Training data distribution\", Counter(y_train))\n",
    "print(\"Testing data distribution\", Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the LogisticRegression model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Logistic Regression classifier\n",
    "lr_clf = LogisticRegression(penalty='l2')\n",
    "\n",
    "# fit model to train data\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model performance\n",
    "float(\"{:.3f}\".format(lr_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import classification_report\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the fitted model to predict labels on the test dataset\n",
    "y_pred_test = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the classification_report\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match each feature with its corresponding weight in the model \n",
    "feature_to_coef = {word: float(\"%.3f\" % coef) for word, coef in zip(vectorizer.get_feature_names_out(), lr_clf.coef_[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top features that are predictive of positive sentiment\n",
    "print(\"Top positive features:\")\n",
    "sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top features that are predictive of negative sentiment\n",
    "print(\"Top negative features:\")\n",
    "sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEQPD697fRr3"
   },
   "source": [
    "_Write your comparison of this model and the previous model(s) here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After comparing some important numbers, I find that the accuracy for the Tfidf model is 0.897, while the CountVectorizer model is 0.883, meaning Tfidf has slightly better accuracy. Similarly, the F1-score for the CountVectorizer model is 0.88, while the Tfidf model achieves 0.90.\n",
    "\n",
    "In addition to the performance metrics, I also compared the top predictive words. The CountVectorizer model produced some unexpected results, such as \"disappoint\" being ranked as the top positive feature, which suggests that the CountVectorizer model more easily influenced by the frequency of word appearances.\n",
    "\n",
    "In contrast, the Tfidf model's top positive and negative words are more reasonable and aligned with sentiment meaning. This may be because TfidfVectorizer considers not only the frequency of a word within a single text, but also its frequency across the entire dataset, which helps highlight the truly important features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWu72VoCphd9"
   },
   "source": [
    "#### **Task-2**: Text Representation with $embeddings$\n",
    "\n",
    "In this task, you will apply embedding techniques to represent text, train a model, and evaluate its performance. Specifically, you will:\n",
    "- Replace `CountVectorizer` with an embedding technique (choose one of word2vec or OpenAI) to create the new feature matrix;\n",
    "    - For `word2vec`, the embedding representation of a sentence is the average embedding representation of all words in the sentence (you can ignore novel words which are not represented in your word2vec embedding space). <br>\n",
    "    - For openAI, you can directly pass the sentence or paragraph to retrieve its embedding representation. <br>\n",
    "- **$fit$** a `LogisticRegression` classifier with the default parameter setting\n",
    "- Evaluate model performance based on the **$classification\\_report$**\n",
    "- Compare the model performance with the previous results using `CountVectorizer` and `TfidfVectorizer` representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load pre-trained Word2Vec model\n",
    "# Model source: https://github.com/eyaler/word2vec-slim\n",
    "# Loading method reference: StackOverflow discussion \"How to load a pre-trained Word2vec MODEL File and reuse it?\"\n",
    "# https://stackoverflow.com/questions/39549248/how-to-load-a-pre-trained-word2vec-model-file-and-reuse-it\n",
    "word2vec_path = './GoogleNews-vectors-negative300-SLIM.bin'\n",
    "w2v_model = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read this article: https://datascience.stackexchange.com/questions/107012/how-to-calculate-the-mean-average-of-word-embedding-and-then-compare-strings-usi\n",
    "# follow the method described in the article\n",
    "# in the article, model.vocab is used, but it is removed in the new gensim version, so I replace it with model.key_to_index\n",
    "def meanEmbeddings(model, words):\n",
    "    words = [word for word in words if word in model.key_to_index]\n",
    "    if len(words) >= 1:\n",
    "        return np.mean(model[words], axis=0)\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the cleaned reviews to sentence embeddings\n",
    "X = []\n",
    "for review in df_data.cleaned_review:\n",
    "    words = review.split()\n",
    "    X.append(meanEmbeddings(w2v_model, words))\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "# check the number of samples, the number of features\n",
    "print(\"X.shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target variable: sentiment labels\n",
    "y = df_data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the train and test data numbers\n",
    "print(\"Training data: X : {}, y : {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Testing data: X : {}, y : {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data distribution\n",
    "print(\"Training data distribution\", Counter(y_train))\n",
    "print(\"Testing data distribution\", Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Logistic Regression classifier\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "# fit model to train data\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model performance\n",
    "float(\"{:.3f}\".format(lr_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the fitted model to predict labels on the test dataset\n",
    "y_pred_test = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the classification_report\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVnh_0HQfX9o"
   },
   "source": [
    "_Write your comparison of this model and the previous model(s) here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After comparing the key performance metrics, it can be seen that the accuracy for the Tfidf model is 0.897, the CountVectorizer model is 0.883, and the Word2Vec model is 0.828. Similarly, the F1-score for the Tfidf model is 0.90, for the CountVectorizer model is 0.88, and for the Word2Vec model is 0.83. Overall, the Tfidf model performs the best among the three.\n",
    "\n",
    "The CountVectorizer method is relatively simple. It only counts the number of times a word appears in the text, without considering the word’s importance across the whole dataset. As a result, it may give too much weight to some common but uninformative words, which affects its performance.\n",
    "\n",
    "TfidfVectorizer improves on this by considering not just how often a word appears in a single text, but also how rare it is across the entire dataset. Words that are common everywhere get lower weights, while more distinctive words are emphasized. This helps the Tfidf model achieve better results overall.\n",
    "\n",
    "Word2Vec represents each word as a 300-dimensional vector based on its meaning. In this task, the sentence embeddings were created by simply averaging all the word vectors in a review. Because of this averaging process, information about the sentence length and the word order was lost. Important details that might help classification were smoothed out, which makes the Word2Vec model performed worse than the other two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBu-Wxg0phd9"
   },
   "source": [
    "#### **Task-3**: model performance with **`penalty='l1'`**\n",
    "\n",
    "In this task, you will explore how the `penalty` parameter affects model performance. Specifically, you will:\n",
    "- Use the original `CountVectorizer` to create the feature matrix\n",
    "- **$fit$** a `LogisticRegression` classifier with `penalty='l1'`\n",
    "- Evaluate model performance to print the **$classification\\_report$**\n",
    "- Print the top-10 positive and negative features\n",
    "- Compare the model performance and top-n features with the original results (which used `penalty='l2'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_Ghw5aUphd9"
   },
   "outputs": [],
   "source": [
    "# lowercase the text and to use the previous self-defined stopwords list to remove stopwords\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words=stopwords, max_df=0.9, min_df=3, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the cleaned reviews to vectors\n",
    "X = vectorizer.fit_transform(df_data.cleaned_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X.shape : \",X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target variable: sentiment labels\n",
    "y = df_data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y.shape : \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data size after splitting\n",
    "print(\"Training data: X : {}, y : {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Testing data: X : {}, y : {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data distribution in train and test\n",
    "print(\"Training data distribution\", Counter(y_train))\n",
    "print(\"Testing data distribution\", Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LogisticRegression classifier use L1\n",
    "lr_clf = LogisticRegression(penalty='l1', solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on training data\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model performance\n",
    "float(\"{:.3f}\".format(lr_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the fitted model to predict labels on the test dataset\n",
    "y_pred_test = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the classification_report\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match each feature with its corresponding weight in the model \n",
    "feature_to_coef = {word: float(\"%.3f\" % coef) for word, coef in zip(vectorizer.get_feature_names_out(), lr_clf.coef_[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top features that are predictive of positive sentiment\n",
    "print(\"Top positive features:\")\n",
    "sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top features that are predictive of negative sentiment\n",
    "print(\"Top negative features:\")\n",
    "sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_9V9f0lfvgW"
   },
   "source": [
    "_Write your comparison of this model and the previous model(s) here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After comparing the results, it can be seen that the overall performance of the L1 model is very similar to the L2 model. The accuracy for both the L1 and L2 models is the same. The F1-scores are also the same. So, in terms of performance, there is no major difference between using L1 or L2.\n",
    "\n",
    "However, when looking at the top predictive features, there is a noticeable difference. The L2 model selected more common and sentiment-related words like \"worst,\" \"awful,\" \"excellent,\" and \"perfect\" for positive and negative predictions, which makes sense in the context of sentiment analysis. But the L1 model picked some unusual and less common words, such as \"warcraft\" and \"nitpick\" for positive sentiment, and \"stinker\" and \"depp\" for negative sentiment.\n",
    "\n",
    "Based on what we learned in class, L2 tends to keep many features and just shrink their weights, so the selected words are more intuitive and general. In contrast, L1 regularization pushes a lot of feature weights to exactly zero. As a result, it may keep rare but highly distinctive words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFUmByPJphd9"
   },
   "source": [
    "**Task-4**: model performance with **`C=0.1` VS `C=1` VS `C=10`**\n",
    "    \n",
    "In this task, you will explore how the `C` parameter affects model performance. Specifically, you will:\n",
    "- Use the original CountVectorizer to create the feature matrix;\n",
    "- **$fit$** a LogisticRegression classifier with C=0.1 and C=10\n",
    "- Evaluate model performance to print the **$classification\\_report$**\n",
    "- Print the top-10 positive and negative features\n",
    "- Compare the model performance and top-n features with the original results from using `C='1'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "324PRWeGphd9"
   },
   "outputs": [],
   "source": [
    "# In the CountVectorizer, lowercase the text and to use a self-defined stopwords list to remove stopwords\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words=stopwords, max_df=0.9, min_df=3, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the cleaned reviews to vectors\n",
    "X = vectorizer.fit_transform(df_data.cleaned_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X.shape : \",X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable: sentiment labels\n",
    "y = df_data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y.shape : \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data size after splitting\n",
    "print(\"Training data: X : {}, y : {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Testing data: X : {}, y : {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data distribution in train and test\n",
    "print(\"Training data distribution\", Counter(y_train))\n",
    "print(\"Testing data distribution\", Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LogisticRegression classifier c=0.1\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.1)\n",
    "\n",
    "# Fit the model on training data\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model performance\n",
    "float(\"{:.3f}\".format(lr_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the fitted model to predict labels on the test dataset\n",
    "y_pred_test = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match each feature with its corresponding weight in the model \n",
    "feature_to_coef = {word: float(\"%.3f\" % coef) for word, coef in zip(vectorizer.get_feature_names_out(), lr_clf.coef_[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top features that are predictive of positive sentiment\n",
    "print(\"Top positive features:\")\n",
    "sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top features that are predictive of negative sentiment\n",
    "print(\"Top negative features:\")\n",
    "sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LogisticRegression classifier c=10\n",
    "lr_clf = LogisticRegression(penalty='l2', C=10)\n",
    "\n",
    "# Fit the model on training data\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model performance\n",
    "float(\"{:.3f}\".format(lr_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the fitted model to predict labels on the test dataset\n",
    "y_pred_test = lr_clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match each feature with its corresponding weight in the model \n",
    "feature_to_coef = {word: float(\"%.3f\" % coef) for word, coef in zip(vectorizer.get_feature_names_out(), lr_clf.coef_[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top features that are predictive of positive sentiment\n",
    "print(\"Top positive features:\")\n",
    "sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top features that are predictive of negative sentiment\n",
    "print(\"Top negative features:\")\n",
    "sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeZnDOVhf9kH"
   },
   "source": [
    "_Write your comparison of this model and the previous model(s) here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After comparing the results, it can be seen that when C=0.1, the model accuracy is 0.893 and the F1-score is 0.89. When C=1, the accuracy is 0.883 and the F1-score is 0.88. When C=10, the accuracy is 0.875 and the F1-score is 0.87. Overall, the model with C=0.1 performs slightly better than the models with C=1 and C=10 in terms of accuracy and F1-score.\n",
    "\n",
    "In addition to the performance metrics, the predictive features were also compared. When C=0.1, the words have smaller weights, and many common and strong sentiment words like \"refreshing,\" \"excellent,\" \"worst,\" and \"waste\" are selected, and they are semantically reasonable. When C=1, the feature weights become a bit larger, and while most of the top words are still reasonable, some problems appear, such as \"disappoint\" being selected as a positive feature, which does not fit the sentiment meaning. When C=10, the feature weights become very large (over 4 or -4), showing signs of overfitting. The problem of \"disappoint\" appearing as a positive feature shows up again, and words like \"generous\" are selected as negative features, which are not typical sentiment words. However, overall, most selected features still make semantic sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMwX0A_8phd-"
   },
   "source": [
    "**Task-5**: Error analysis for the best model\n",
    "\n",
    "Pick the best model from the above explorations. Then, in this task, conduct an error analysis to understand and explain where the model fails. From the samples where the model fail, can you identify any patterns to explain the failure?\n",
    "\n",
    "_NB_: If a `TfidfVectorizer` or `CountVectorizer` model is the best, then you can use our `interpretation` function from above. If they are not, you will try to summarize patterns from highly misclassified documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I think the model using TFIDF is the best one based on the previous comparisons.\n",
    "# To make sure I use the correct TFIDF model, I re-run the model training from the beginning.\n",
    "# Also, for better error analysis, I split the data by indices first, and then use these indices to split the actual data matrices.\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words=stopwords, max_df=0.9, min_df=3, ngram_range=(1,1))\n",
    "X = vectorizer.fit_transform(df_data.cleaned_review)\n",
    "y = df_data.label.values \n",
    "\n",
    "train_idx, test_idx = train_test_split(np.arange(df_data.shape[0]), test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "X_train = X[train_idx]\n",
    "y_train = y[train_idx]\n",
    "\n",
    "X_test = X[test_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "lr_clf = LogisticRegression(penalty='l2')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Briefly check the prediction results\n",
    "df_test = df_data.iloc[test_idx]\n",
    "df_test['pred_label'] = y_pred_test\n",
    "df_test.head(3)[['review','label','pred_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "py4lX86Rphd-"
   },
   "outputs": [],
   "source": [
    "# Select reviews where the true label and the predicted label are different\n",
    "df_test[df_test['label'] != df_test['pred_label']].head()[['review','label','pred_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab one misclassified review for further analysis\n",
    "df_data.loc[40146]['cleaned_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "# use colors for convenience of viewing,\n",
    "RED = '\\033[1;31;48m'\n",
    "BLUE = '\\033[1;34;48m'\n",
    "END = '\\033[1;37;0m'\n",
    "\n",
    "def interpretation(text, vectorizer, wrap_length=250, use_color=True):\n",
    "    \"\"\"\n",
    "    Annotate each word feature with the learned coefficient, and color based on\n",
    "    coefficient direction\n",
    "    \"\"\"\n",
    "    # Make the annotated string\n",
    "    analysis = []\n",
    "    for wd in text.split():\n",
    "        if wd in vectorizer.vocabulary_:\n",
    "            wd_id = vectorizer.vocabulary_[wd]\n",
    "            to_append = wd\n",
    "\n",
    "            # Red is more negative, blue is more positive\n",
    "            if use_color and lr_clf.coef_[0][wd_id] < 0:\n",
    "                to_append = RED + to_append + END\n",
    "            elif use_color and lr_clf.coef_[0][wd_id] > 0:\n",
    "                to_append = BLUE + to_append + END\n",
    "\n",
    "            to_append = to_append+'('+(\"%.3f\" % lr_clf.coef_[0][wd_id])+')'\n",
    "\n",
    "\n",
    "            analysis.append(to_append)\n",
    "        else:\n",
    "            analysis.append(wd)\n",
    "    result = ' '.join(analysis)\n",
    "\n",
    "    # Wrap the string for easier viewing\n",
    "    wrapper = textwrap.TextWrapper(width=wrap_length)\n",
    "    result = wrapper.fill(text=result)\n",
    "\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation(df_data.loc[40146]['cleaned_review'],vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the samples where the model fail, the patterns to explain the failure?\n",
    "After analyzing the misclassified samples, I observed some common patterns.\n",
    "\n",
    "First, many misclassified reviews tend to be relatively long and contain a lot of descriptive information. They often read like a narrative or explanation, which makes it harder for the model to capture a strong emotional tone.\n",
    "\n",
    "Second, many misclassified reviews contain mixed sentiment. For example, a review may mention some positive aspects (such as \"good performance\" or \"nice visuals\") while also pointing out negative aspects (like \"weak story\" or \"boring pacing\") within the same text. This mixed tone makes it difficult for the model to confidently predict a single label.\n",
    "\n",
    "Third, some reviews use a structure where the writer first points out many negative aspects but concludes with an overall positive sentiment. For instance, a review might start by listing all the disappointing parts but end with \"however, overall it was still a good experience.\" Because the negative words dominate the beginning and body of the text, the model may incorrectly predict it as negative even though the true label is positive.\n",
    "\n",
    "Lastly, some words that are important for sentiment may have different meanings depending on the context. For example, the word \"horror\" could be positive when praising a horror film, but negative when criticizing production quality. Since the TFIDF model treats words independently without understanding context, this can easily lead to misclassification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLDGmNJWzn_o"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "In this assignment, we built a binary sentiment classifier based on the IMDb movie reviews dataset. We proceeded in a few steps: <br>\n",
    "- **Data preprocessing**: we first explored and cleaned the data, and checked the distribution of the target variable.<br>\n",
    "- **Text feature representation**: we then explored text data representation with CountVectorizer, TfidfVectorizer, and embedding techniques to convert the texts into 2D feature matrix.\n",
    "- **Model selection and parameter tuning**: we explored models with different parameter settings (l1 VS l2 penalty, and different C values).\n",
    "- **Model evaluation**: We used an 80:20 (respective) split to get training and testing sets, and then trained a `LogisticRegression` classifier on the training data (with the best parameter settings), before evaluating model performance on the testing data. We reported the model performance using precision, recall, f1, and roc_auc. <br>\n",
    "- **Model explanation**: we checked top-N words that are most predictive of positive and negative sentiments to qualitatively explain the model performance.\n",
    "- **Error analysis**: we conducted an error analysis by exploring and explaining samples where the model made errors.\n",
    "\n",
    "\n",
    "With the above exploration, we can further improve model performance from multiple aspects (e.g., text data processing and representation, different models and hyperparameters, different regularization techniques).\n",
    "\n",
    "In addition to the technical improvements, we could also improve model performance by considering the context of the task itself. For example, we might represent each sample with additional factors that are predictive of sentiment (e.g., Part-of-Speech tags, N-grams)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
